{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "848c6682",
   "metadata": {},
   "source": [
    "# Plan-and-Execute \n",
    "\n",
    "The core idea is to first come up with a multi-step plan, and then go through that plan one item at a time. After accomplishing a particular task, you can then revisit the plan and modify as appropriate.\n",
    "\n",
    "paper:\n",
    "https://arxiv.org/abs/2305.04091\n",
    "\n",
    "source:\n",
    "https://github.com/langchain-ai/langgraph/blob/c7306f7aed68334a4287b4eed9c05444e4b095a6/docs/docs/tutorials/plan-and-execute/plan-and-execute.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d91acfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define tools \n",
    "import os\n",
    "import yaml\n",
    "import requests\n",
    "from langchain.tools import tool\n",
    "from xml.etree import ElementTree\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "@tool\n",
    "def arxiv_search_tool(query: str) -> list:\n",
    "    \"\"\"Search Arxiv for the given query and return a list of results (title: url).\"\"\"\n",
    "    url = \"http://export.arxiv.org/api/query\"\n",
    "    params = {\"search_query\": query, \"start\": 0, \"max_results\": 5}\n",
    "    try:\n",
    "        resp = requests.get(url, params=params, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        root = ElementTree.fromstring(resp.content)\n",
    "        ns = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "        results = []\n",
    "        for entry in root.findall('atom:entry', ns):\n",
    "            title_elem = entry.find('atom:title', ns)\n",
    "            link_elem = entry.find('atom:id', ns)\n",
    "            title = title_elem.text.strip() if title_elem is not None else \"No Title\"\n",
    "            link = link_elem.text.strip() if link_elem is not None else \"\"\n",
    "            if link:\n",
    "                results.append(f\"{title}: {link}\")\n",
    "        return results or [\"Arxiv: No relevant results found.\"]\n",
    "    except Exception as e:\n",
    "        return [f\"Arxiv search error: {e}\"]\n",
    "\n",
    "@tool\n",
    "def duckduckgo_search_tool(query: str) -> list:\n",
    "    \"\"\"Search DuckDuckGo for the given query and return a list of results.\"\"\"\n",
    "    try:\n",
    "        # Use DDGS for robust search, region set to 'cn-zh' for Chinese\n",
    "        results = DDGS().text(query, region=\"cn-zh\", safesearch=\"off\", max_results=10)\n",
    "        output = []\n",
    "        for item in results:\n",
    "            title = item.get('title')\n",
    "            url = item.get('href')\n",
    "            if title and url:\n",
    "                output.append(f\"{title}: {url}\")\n",
    "        return output or [\"DuckDuckGo: No relevant results found.\"]\n",
    "    except Exception as e:\n",
    "        return [f\"DuckDuckGo search error: {e}\"]\n",
    "\n",
    "tools = [arxiv_search_tool, duckduckgo_search_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c25b6a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with anything you need. ðŸ˜Š How about you? How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "### define execution agent\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.deepseek.com\", \n",
    "    api_key=\"sk-3b458ee0624f41e1b8c589e74be23e44\",\n",
    "    model_name=\"deepseek-chat\"\n",
    "    )\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.siliconflow.cn/v1\",\n",
    "#     model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "#     api_key=\"sk-ykbiglqspirbapnzjvrasbuhboizzqhhhjupwcwxkvhcktod\"\n",
    "# )\n",
    "\n",
    "result = llm.invoke('Hello, how are you?')\n",
    "result.pretty_print()\n",
    "researcher_agent = create_react_agent(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a175577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who is the winnner of the us open', additional_kwargs={}, response_metadata={}, id='b31b477f-4d52-4e7a-af74-67bde01deed8'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '01971b69652ad5d42954cee1dbf646c6', 'function': {'arguments': '{\"query\": \"2023 US Open winner\"}', 'name': 'duckduckgo_search_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 264, 'total_tokens': 294, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': '', 'id': '01971b695e160b10bd591564fde851a1', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--73f80672-4661-41e7-8a4f-77fed99a332b-0', tool_calls=[{'name': 'duckduckgo_search_tool', 'args': {'query': '2023 US Open winner'}, 'id': '01971b69652ad5d42954cee1dbf646c6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 264, 'output_tokens': 30, 'total_tokens': 294, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='[\"2023 US Open (tennis) - Wikipedia: https://en.wikipedia.org/wiki/2023_US_Open_(tennis)\", \"Novak Djokovic wins 24th Grand Slam singles title at 2023 US Open: https://www.usopen.org/en_US/news/articles/2023-09-10/novak_djokovic_wins_24th_grand_slam_singles_title_at_2023_us_open.html\", \"US Open 2023 Winners: Complete list of men\\'s and women\\'s singles and ...: https://www.sportskeeda.com/tennis/news-us-open-2023-winners-complete-list-men-s-women-s-singles-doubles-champions\", \"US Open 2023 Winners Complete list - adda247: https://currentaffairs.adda247.com/us-open-2023-winners-complete-list/\", \"2023 US Open - Men\\'s singles - Wikipedia: https://en.wikipedia.org/wiki/2023_US_Open_â€“_Men\\'s_singles\", \"Who won the U.S. Open in 2023? Complete scores, results, highlights ...: https://www.sportingnews.com/us/golf/news/us-open-2023-live-scores-results-leaderboard/jbmxrpro5jc37drgq8e2lehn\", \"Novak Djokovic beats Daniil Medvedev to win US Open men\\'s final ... - CNN: https://www.cnn.com/2023/09/10/tennis/novak-djokovic-daniil-medvedev-us-open-spt-intl/index.html\", \"Novak Djokovic tops Daniil Medvedev to win US Open, 24th major: https://www.espn.com/tennis/story/_/id/38373910/novak-djokovic-beats-daniil-medvedev-win-2023-us-open-24th-major-title\", \"US Open 2023 results: Novak Djokovic wins 24th major by beating ... - BBC: https://www.bbc.com/sport/tennis/66766337\", \"Novak Djokovic defeats Daniil Medvedev to win 2023 US Open and 24th ...: https://www.telegraph.co.uk/tennis/2023/09/10/novak-djokovic-vs-daniil-medvedev-us-open-final-2023-live/\"]', name='duckduckgo_search_tool', id='702a89bc-06d6-4967-889c-adc5d84460da', tool_call_id='01971b69652ad5d42954cee1dbf646c6'),\n",
       "  AIMessage(content=\"The winner of the 2023 US Open in men's singles tennis is Novak Djokovic. He defeated Daniil Medvedev in the final to secure his 24th Grand Slam singles title. Here is one of the sources confirming this:\\n\\n- [Novak Djokovic wins 24th Grand Slam singles title at 2023 US Open](https://www.usopen.org/en_US/news/articles/2023-09-10/novak_djokovic_wins_24th_grand_slam_singles_title_at_2023_us_open.html)\\n\\nIf you're interested in the women's singles or other categories, let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 147, 'prompt_tokens': 880, 'total_tokens': 1027, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen2.5-72B-Instruct', 'system_fingerprint': '', 'id': '01971b696cc554e062cdadde7adb032c', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--0ebd3cee-6755-4c26-b643-8b1fad248733-0', usage_metadata={'input_tokens': 880, 'output_tokens': 147, 'total_tokens': 1027, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "researcher_agent.invoke({\"messages\": [(\"user\", \"who is the winnner of the us open\")]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e153178b",
   "metadata": {},
   "source": [
    "### Define the State and Planning Step\n",
    "\n",
    "State definition.\n",
    "\n",
    "First, we will need to track the **current plan**. Let's represent that as a list of strings.\n",
    "\n",
    "Next, we should track previously **executed steps**. Let's represent that as a list of tuples (these tuples will contain the step and then the result)\n",
    "\n",
    "Finally, we need to have some state to represent the final response as well as the original input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cafedc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab8df0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "planner = planner_prompt | llm.with_structured_output(Plan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297af1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnprocessableEntityError",
     "evalue": "Failed to deserialize the JSON body into the target type: response_format: response_format.type `json_schema` is unavailable now at line 1 column 858",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnprocessableEntityError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplanner\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is the hometown of the current Australia open winner?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3033\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3034\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3036\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5409\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5411\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5414\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5415\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5418\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5419\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    360\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    365\u001b[39m     **kwargs: Any,\n\u001b[32m    366\u001b[39m ) -> BaseMessage:\n\u001b[32m    367\u001b[39m     config = ensure_config(config)\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    369\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    380\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    940\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    944\u001b[39m     **kwargs: Any,\n\u001b[32m    945\u001b[39m ) -> LLMResult:\n\u001b[32m    946\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    763\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    765\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m         )\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    774\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1010\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:935\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    933\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    934\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m935\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    937\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    153\u001b[39m         response_format=response_format,\n\u001b[32m    154\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    155\u001b[39m         input_tools=tools,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:1276\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1264\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1271\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1272\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1273\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1274\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1275\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:949\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    946\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    947\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:1057\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1054\u001b[39m         err.response.read()\n\u001b[32m   1056\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1060\u001b[39m     cast_to=cast_to,\n\u001b[32m   1061\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1065\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1066\u001b[39m )\n",
      "\u001b[31mUnprocessableEntityError\u001b[39m: Failed to deserialize the JSON body into the target type: response_format: response_format.type `json_schema` is unavailable now at line 1 column 858"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "try:\n",
    "    response = planner.invoke({\"messages\": [(\"user\", \"what is the hometown of the current Australia open winner?\")]})\n",
    "    print(json.dumps(response, indent=2))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e476f396",
   "metadata": {},
   "source": [
    "### Re-Plan Step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ab94e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response. \"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "\n",
    "replanner_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"For the given objective, come up with a simple step by step plan. \\\n",
    "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
    "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
    "\n",
    "Your objective was this:\n",
    "{input}\n",
    "\n",
    "Your original plan was this:\n",
    "{plan}\n",
    "\n",
    "You have currently done the follow steps:\n",
    "{past_steps}\n",
    "\n",
    "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done. Do not return previously done steps as part of the plan.\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "replanner = replanner_prompt | llm.with_structured_output(Act)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fd0974",
   "metadata": {},
   "source": [
    "## Create the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da0cf8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await agent_executor.ainvoke(\n",
    "        {\"messages\": [(\"user\", task_formatted)]}\n",
    "    )\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)],\n",
    "    }\n",
    "\n",
    "\n",
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\"plan\": plan.steps}\n",
    "\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    output = await replanner.ainvoke(state)\n",
    "    if isinstance(output.action, Response):\n",
    "        return {\"response\": output.action.response}\n",
    "    else:\n",
    "        return {\"plan\": output.action.steps}\n",
    "\n",
    "\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return END\n",
    "    else:\n",
    "        return \"agent\"\n",
    "\n",
    "def build_graph():\n",
    "    workflow = StateGraph(PlanExecute)\n",
    "\n",
    "    # Add the plan node\n",
    "    workflow.add_node(\"planner\", plan_step)\n",
    "    # Add the execution step\n",
    "    workflow.add_node(\"agent\", execute_step)\n",
    "    # Add a replan node\n",
    "    workflow.add_node(\"replan\", replan_step)\n",
    "    workflow.add_edge(START, \"planner\")\n",
    "    # From plan we go to agent\n",
    "    workflow.add_edge(\"planner\", \"agent\")\n",
    "    # From agent, we replan\n",
    "    workflow.add_edge(\"agent\", \"replan\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"replan\",\n",
    "        # Next, we pass in the function that will determine which node is called next.\n",
    "        should_end,\n",
    "        [\"agent\", END],\n",
    "    )\n",
    "\n",
    "    # Finally, we compile it!\n",
    "    # This compiles it into a LangChain Runnable,\n",
    "    # meaning you can use it as you would any other runnable\n",
    "    app = workflow.compile()\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "913b07d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "app = build_graph()\n",
    "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875746cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Plan\n  Input should be an object [type=model_type, input_value=1.3010521711127168, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m50\u001b[39m}\n\u001b[32m      2\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwhat is the hometown of the mens 2024 Australia open winner?\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m app.astream(inputs, config=config):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m event.items():\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m k != \u001b[33m\"\u001b[39m\u001b[33m__end__\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2759\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2753\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2754\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   2755\u001b[39m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2756\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2757\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   2758\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2759\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2760\u001b[39m         loop.tasks.values(),\n\u001b[32m   2761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2762\u001b[39m         retry_policy=\u001b[38;5;28mself\u001b[39m.retry_policy,\n\u001b[32m   2763\u001b[39m         get_waiter=get_waiter,\n\u001b[32m   2764\u001b[39m     ):\n\u001b[32m   2765\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2766\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   2767\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langgraph\\pregel\\runner.py:283\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    281\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    284\u001b[39m         t,\n\u001b[32m    285\u001b[39m         retry_policy,\n\u001b[32m    286\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    287\u001b[39m         configurable={\n\u001b[32m    288\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    289\u001b[39m                 _acall,\n\u001b[32m    290\u001b[39m                 weakref.ref(t),\n\u001b[32m    291\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    292\u001b[39m                 retry=retry_policy,\n\u001b[32m    293\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    294\u001b[39m                 schedule_task=\u001b[38;5;28mself\u001b[39m.schedule_task,\n\u001b[32m    295\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    296\u001b[39m                 reraise=reraise,\n\u001b[32m    297\u001b[39m                 loop=loop,\n\u001b[32m    298\u001b[39m             ),\n\u001b[32m    299\u001b[39m         },\n\u001b[32m    300\u001b[39m     )\n\u001b[32m    301\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langgraph\\pregel\\retry.py:128\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policies, stream, configurable)\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langgraph\\utils\\runnable.py:672\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    670\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    671\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    673\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    674\u001b[39m         )\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    676\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langgraph\\utils\\runnable.py:440\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mplan_step\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplan_step\u001b[39m(state: PlanExecute):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     plan = \u001b[38;5;28;01mawait\u001b[39;00m planner.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [(\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, state[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m])]})\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mplan\u001b[39m\u001b[33m\"\u001b[39m: plan.steps}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3075\u001b[39m, in \u001b[36mRunnableSequence.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3073\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3074\u001b[39m                 part = functools.partial(step.ainvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[32m-> \u001b[39m\u001b[32m3075\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3076\u001b[39m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5429\u001b[39m, in \u001b[36mRunnableBindingBase.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5422\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m   5424\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5427\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5428\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5429\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.ainvoke(\n\u001b[32m   5430\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5431\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5432\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5433\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:392\u001b[39m, in \u001b[36mBaseChatModel.ainvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    384\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m     **kwargs: Any,\n\u001b[32m    390\u001b[39m ) -> BaseMessage:\n\u001b[32m    391\u001b[39m     config = ensure_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m     llm_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate_prompt(\n\u001b[32m    393\u001b[39m         [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    394\u001b[39m         stop=stop,\n\u001b[32m    395\u001b[39m         callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    396\u001b[39m         tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    397\u001b[39m         metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    398\u001b[39m         run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    399\u001b[39m         run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    400\u001b[39m         **kwargs,\n\u001b[32m    401\u001b[39m     )\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m, llm_result.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:958\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m    951\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    955\u001b[39m     **kwargs: Any,\n\u001b[32m    956\u001b[39m ) -> LLMResult:\n\u001b[32m    957\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m958\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m    959\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m    960\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:916\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    904\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    905\u001b[39m             *[\n\u001b[32m    906\u001b[39m                 run_manager.on_llm_end(\n\u001b[32m   (...)\u001b[39m\u001b[32m    914\u001b[39m             ]\n\u001b[32m    915\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m    917\u001b[39m flattened_outputs = [\n\u001b[32m    918\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[32m    919\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    920\u001b[39m ]\n\u001b[32m    921\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1084\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1082\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1083\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1084\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1085\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1086\u001b[39m     )\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1088\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1135\u001b[39m, in \u001b[36mBaseChatOpenAI._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1133\u001b[39m payload.pop(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1135\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.root_async_client.beta.chat.completions.parse(\n\u001b[32m   1136\u001b[39m         **payload\n\u001b[32m   1137\u001b[39m     )\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m openai.BadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1139\u001b[39m     _handle_openai_bad_request(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:437\u001b[39m, in \u001b[36mAsyncCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    432\u001b[39m         response_format=response_format,\n\u001b[32m    433\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    434\u001b[39m         input_tools=tools,\n\u001b[32m    435\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    438\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    439\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m    440\u001b[39m         {\n\u001b[32m    441\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m    442\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    443\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m    444\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m    445\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m    446\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m    447\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m    448\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m    449\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m    450\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m    451\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    452\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m    453\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m    454\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m    455\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m    456\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m    457\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m    458\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: _type_to_response_format(response_format),\n\u001b[32m    459\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m    460\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m    461\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m    462\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    463\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    464\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m    465\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m    466\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m    467\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m    468\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m    469\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m    470\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m    471\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m    472\u001b[39m         },\n\u001b[32m    473\u001b[39m         completion_create_params.CompletionCreateParams,\n\u001b[32m    474\u001b[39m     ),\n\u001b[32m    475\u001b[39m     options=make_request_options(\n\u001b[32m    476\u001b[39m         extra_headers=extra_headers,\n\u001b[32m    477\u001b[39m         extra_query=extra_query,\n\u001b[32m    478\u001b[39m         extra_body=extra_body,\n\u001b[32m    479\u001b[39m         timeout=timeout,\n\u001b[32m    480\u001b[39m         post_parser=parser,\n\u001b[32m    481\u001b[39m     ),\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;66;03m# in the `parser` function above\u001b[39;00m\n\u001b[32m    484\u001b[39m     cast_to=cast(Type[ParsedChatCompletion[ResponseFormatT]], ChatCompletion),\n\u001b[32m    485\u001b[39m     stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    486\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:1805\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1793\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1800\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1801\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1802\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1803\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1804\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:1495\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1493\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1496\u001b[39m     cast_to=cast_to,\n\u001b[32m   1497\u001b[39m     options=options,\n\u001b[32m   1498\u001b[39m     stream=stream,\n\u001b[32m   1499\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1500\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1501\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:1602\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1599\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1600\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1603\u001b[39m     cast_to=cast_to,\n\u001b[32m   1604\u001b[39m     options=options,\n\u001b[32m   1605\u001b[39m     response=response,\n\u001b[32m   1606\u001b[39m     stream=stream,\n\u001b[32m   1607\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1608\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1609\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_base_client.py:1699\u001b[39m, in \u001b[36mAsyncAPIClient._process_response\u001b[39m\u001b[34m(self, cast_to, options, response, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(response.request.headers.get(RAW_RESPONSE_HEADER)):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, api_response)\n\u001b[32m-> \u001b[39m\u001b[32m1699\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m api_response.parse()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_response.py:432\u001b[39m, in \u001b[36mAsyncAPIResponse.parse\u001b[39m\u001b[34m(self, to)\u001b[39m\n\u001b[32m    430\u001b[39m parsed = \u001b[38;5;28mself\u001b[39m._parse(to=to)\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_given(\u001b[38;5;28mself\u001b[39m._options.post_parser):\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     parsed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(parsed, BaseModel):\n\u001b[32m    435\u001b[39m     add_request_id(parsed, \u001b[38;5;28mself\u001b[39m.request_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:431\u001b[39m, in \u001b[36mAsyncCompletions.parse.<locals>.parser\u001b[39m\u001b[34m(raw_completion)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_chat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_completion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py:110\u001b[39m, in \u001b[36mparse_chat_completion\u001b[39m\u001b[34m(response_format, input_tools, chat_completion)\u001b[39m\n\u001b[32m    100\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    101\u001b[39m                 tool_calls.append(tool_call)\n\u001b[32m    103\u001b[39m     choices.append(\n\u001b[32m    104\u001b[39m         construct_type_unchecked(\n\u001b[32m    105\u001b[39m             type_=cast(Any, ParsedChoice)[solve_response_format_t(response_format)],\n\u001b[32m    106\u001b[39m             value={\n\u001b[32m    107\u001b[39m                 **choice.to_dict(),\n\u001b[32m    108\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    109\u001b[39m                     **message.to_dict(),\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mparsed\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mmaybe_parse_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    114\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m: tool_calls \u001b[38;5;28;01mif\u001b[39;00m tool_calls \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    115\u001b[39m                 },\n\u001b[32m    116\u001b[39m             },\n\u001b[32m    117\u001b[39m         )\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    121\u001b[39m     ParsedChatCompletion[ResponseFormatT],\n\u001b[32m    122\u001b[39m     construct_type_unchecked(\n\u001b[32m   (...)\u001b[39m\u001b[32m    128\u001b[39m     ),\n\u001b[32m    129\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py:161\u001b[39m, in \u001b[36mmaybe_parse_content\u001b[39m\u001b[34m(response_format, message)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmaybe_parse_content\u001b[39m(\n\u001b[32m    156\u001b[39m     *,\n\u001b[32m    157\u001b[39m     response_format: \u001b[38;5;28mtype\u001b[39m[ResponseFormatT] | ResponseFormatParam | NotGiven,\n\u001b[32m    158\u001b[39m     message: ChatCompletionMessage | ParsedChatCompletionMessage[\u001b[38;5;28mobject\u001b[39m],\n\u001b[32m    159\u001b[39m ) -> ResponseFormatT | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_rich_response_format(response_format) \u001b[38;5;129;01mand\u001b[39;00m message.content \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message.refusal:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\lib\\_parsing\\_completions.py:221\u001b[39m, in \u001b[36m_parse_content\u001b[39m\u001b[34m(response_format, content)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_content\u001b[39m(response_format: \u001b[38;5;28mtype\u001b[39m[ResponseFormatT], content: \u001b[38;5;28mstr\u001b[39m) -> ResponseFormatT:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_basemodel_type(response_format):\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseFormatT, \u001b[43mmodel_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass_like_type(response_format):\n\u001b[32m    224\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m PYDANTIC_V2:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\openai\\_compat.py:169\u001b[39m, in \u001b[36mmodel_parse_json\u001b[39m\u001b[34m(model, data)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_parse_json\u001b[39m(model: \u001b[38;5;28mtype\u001b[39m[_ModelT], data: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mbytes\u001b[39m) -> _ModelT:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m PYDANTIC_V2:\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.parse_raw(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Anaconda3\\envs\\lang\\Lib\\site-packages\\pydantic\\main.py:744\u001b[39m, in \u001b[36mBaseModel.model_validate_json\u001b[39m\u001b[34m(cls, json_data, strict, context, by_alias, by_name)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    740\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    741\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    742\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Plan\n  Input should be an object [type=model_type, input_value=1.3010521711127168, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
      "During task with name 'planner' and id 'ff0ab346-e908-1a8a-c425-43f9c34be407'"
     ]
    }
   ],
   "source": [
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\"input\": \"what is the hometown of the mens 2024 Australia open winner?\"}\n",
    "\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dddd743",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
